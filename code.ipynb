{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b522c33d",
   "metadata": {
    "id": "b522c33d"
   },
   "source": [
    "# Transformations and Representations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c57fe",
   "metadata": {
    "id": "3a6c57fe"
   },
   "source": [
    "## 1. 3D Data and Open3D\n",
    "\n",
    "1. Please find mesh files in **data/Q1** folder. Using these mesh files and your own creativity/visualisation, create a \"Table\" **pointcloud** scene. The table scene should be realistic, scaled appropiately. Use all the meshes given in the folder and treat them as objects kept on the table. \n",
    "\n",
    "    You are expected to perform different functions on the individual mesh files: first convert the mesh files to pointclouds and on each pointcloud perform operations such as scaling, rotation, translation. Next, visualize them together. The visualization should represent a pointcloud of a realistic table scene. Save the scene as **.pcd** file. \n",
    "\n",
    "    **Please do not copy as we may use your contribution to create a table top dataset.**\n",
    "\n",
    "    Refer below image for example of a table-top scene:\n",
    "\n",
    "    <img src=\"img/1.jpeg\"  width=\"500\" >\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. Use the final table scene pointcloud obtained from part 1. \n",
    "    - Use Open3D to generate partial pointclouds from different camera views (at least 4 views). This means, that you need to crop or capture the points in the pointcloud that are visible only from a given viewpoint. \n",
    "    - Using these partial pointclouds, you are now expected to generate the full scene pointcloud back by registering the pointclouds to a global frame. Save the partial and reconstructed pointclouds in different files. \n",
    "    - **[ BONUS ]** Finally, compute the error using \"Chamfer's Distance (CD)\" between the ground truth scene pointcloud and the reconstructed pointcloud. Perform an analysis: \n",
    "      1. Why is the CD not 0?\n",
    "      2. How does the CD change as the number of viewpoints increase / decrease? \n",
    "      3. Can we optimize the viewpoints (by hit and trial) such that the CD reduces?\n",
    "\n",
    "Refer the following link for solving Q1:\n",
    "- Hidden-Point-Removal Open3D API: http://www.open3d.org/docs/latest/tutorial/Basic/pointcloud.html#Hidden-point-removal\n",
    "\n",
    "- Chamfer's Distance:  https://pytorch3d.readthedocs.io/en/latest/modules/loss.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3174677",
   "metadata": {
    "id": "e3174677"
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import torch\n",
    "\n",
    "boat = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/boat.pcd\")\n",
    "car = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/car.pcd\")\n",
    "table = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/table.pcd\")\n",
    "laptop = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/laptop.pcd\")\n",
    "plane = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/plane.pcd\")\n",
    "trashcan = o3d.io.read_point_cloud(\"./results/q1/pcdObjects/trashcan.pcd\")\n",
    "\n",
    "pcds = []\n",
    "pcds.append(table)\n",
    "\n",
    "R = laptop.get_rotation_matrix_from_xyz((np.pi/2, np.pi/2, 0))\n",
    "laptop.rotate(R)\n",
    "laptop.scale(20, center=laptop.get_center())\n",
    "laptop.translate((85, 90, 32))\n",
    "pcds.append(laptop)\n",
    "\n",
    "R = car.get_rotation_matrix_from_xyz((np.pi/2, -np.pi/4, 0))\n",
    "car.rotate(R)\n",
    "car.translate((95, 90, 30))\n",
    "car.scale(10, center=car.get_center())\n",
    "pcds.append(car)\n",
    "\n",
    "R = trashcan.get_rotation_matrix_from_xyz((np.pi/2, 0, 0))\n",
    "trashcan.rotate(R)\n",
    "trashcan.translate((98, 106, 33.3))\n",
    "trashcan.scale(13, center=trashcan.get_center())\n",
    "pcds.append(trashcan)\n",
    "\n",
    "R = plane.get_rotation_matrix_from_xyz((np.pi/2, np.pi/4, 0))\n",
    "plane.rotate(R)\n",
    "plane.translate((85, 105, 29.5))\n",
    "plane.scale(30, center=plane.get_center())\n",
    "pcds.append(plane)\n",
    "\n",
    "R = boat.get_rotation_matrix_from_xyz((np.pi/2, -np.pi/2, 0))\n",
    "boat.rotate(R)\n",
    "boat.translate((88, 75, 30))\n",
    "boat.scale(20, center=boat.get_center())\n",
    "pcds.append(boat)\n",
    "\n",
    "singlePcd = o3d.geometry.PointCloud()\n",
    "for i in pcds:\n",
    "    singlePcd += i\n",
    "# o3d.visualization.draw_geometries([singlePcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410fc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPcds = []\n",
    "diameter = np.linalg.norm(np.asarray(singlePcd.get_max_bound()) - np.asarray(singlePcd.get_min_bound()))\n",
    "radius = diameter * 100\n",
    "\n",
    "camera = [0, 0, diameter]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd1 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd1])\n",
    "newPcds.append(pcd1)\n",
    "\n",
    "camera = [0, diameter, 0]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd2 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd2])\n",
    "newPcds.append(pcd2)\n",
    "\n",
    "camera = [diameter, 0, 3*diameter]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd3 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd3])\n",
    "newPcds.append(pcd3)\n",
    "\n",
    "camera = [diameter, 0, diameter]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd4 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd4])\n",
    "newPcds.append(pcd4)\n",
    "\n",
    "camera = [diameter, 2*diameter, diameter]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd5 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd5])\n",
    "newPcds.append(pcd5)\n",
    "\n",
    "camera = [diameter, diameter, 0]\n",
    "_, pt_map = singlePcd.hidden_point_removal(camera, radius)\n",
    "pcd6 = singlePcd.select_by_index(pt_map)\n",
    "# o3d.visualization.draw_geometries([pcd6])\n",
    "newPcds.append(pcd6)\n",
    "\n",
    "reconstructedPcd = o3d.geometry.PointCloud()\n",
    "for i in newPcds:\n",
    "    reconstructedPcd += i\n",
    "\n",
    "# o3d.visualization.draw_geometries([reconstructedPcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "aray = np.asarray(reconstructedPcd.points)\n",
    "array = np.asarray(aray)\n",
    "x = torch.FloatTensor(aray)\n",
    "x.unsqueeze_(0)\n",
    "# print(x.shape)\n",
    "aray2 = np.asarray(singlePcd.points)\n",
    "y = torch.FloatTensor(aray2)\n",
    "y.unsqueeze_(0)\n",
    "# print(y.shape)\n",
    "chamfer_distance(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e2242",
   "metadata": {},
   "source": [
    "1. Chamfers Distance tells us how much the point clouds differ from each other. It's basically a loss function for point clouds. If CD == 0, then it means that the point clouds are identical. The number of points in both the point clouds \"reconstructedPcd\" and \"singlePcd\" are different as the reconstructed point cloud is just a merged version of point clouds from different views. It does not completely reconstruct the scene. The scene has holes and is not completed.\n",
    "2. With increase in viewpoints, the scene gets completed and the size of holes/ number of holes in the reconstructed pcd decrease. Hence, the CD decreases with increases in viewpoints.\n",
    "3. Yes, we can choose the viewpoints such that the CD decreases. If we are limited to a finite number of viewpoints, then choosing viewpoints such that maximum number of unique points get covered will result in a lower CD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d688be4e",
   "metadata": {
    "id": "d688be4e"
   },
   "source": [
    "## 2. Euler Angles, Rotation Matrices, and Quaternions\n",
    "1. Write a function (do not use inbuilt libraries for this question):\n",
    "    - that returns a rotation matrix given the angles $\\alpha$, $\\beta$, and $\\gamma$ in radians (X-Y-Z).\n",
    "    - to convert a rotation matrix to quaternion and vice versa. \n",
    "\n",
    "2. What is a Gimbal lock? Suppose an airplane increases its pitch from $0°$ to $90°$. \n",
    "\n",
    "    - Let $R_{gmb\\beta}$ be the rotation matrix for $\\beta=90°$. Find $R_{gmb\\beta}$.\n",
    "    - Consider the point $p = [0, 1, 0]ᵀ $ on the pitched airplane, i.e. the tip of the wing. Does there exist any $α , γ$ such that $p_{new} = R_{gmb\\beta}\\; p$ for:\n",
    "      1. $p_{new} = [1, 0, 0]ᵀ $\n",
    "      2. For some  $p_{new}$ on the XY unit circle?\n",
    "      3. For some  $p_{new}$ on the YZ unit circle?\n",
    "      \n",
    "      Show your work for all three parts and briefly explain your reasoning. Why is $\\beta=90°$  a “certain problematic value”?\n",
    "\n",
    "    <img src=\"img/2.3.jpeg\"  width=\"500\" ><br>\n",
    "    \n",
    "    <img src=\"img/2.1.jpeg\"  width=\"500\" ><br>\n",
    "\n",
    "    <img src=\"img/2.2.jpeg\"  width=\"500\" >\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a3b89f6",
   "metadata": {
    "id": "4a3b89f6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Function Function that returns rotation matrix given angles alpha, beta and gamma (in radians)\n",
    "def rotMatrix(gamma, beta, alpha):\n",
    "    matrix = []\n",
    "    row1 = []\n",
    "    row1.append(math.cos(beta) * math.cos(alpha))\n",
    "    row1.append(math.sin(gamma)*math.sin(beta)*math.cos(alpha) - math.cos(gamma)*math.sin(alpha))\n",
    "    row1.append(math.cos(gamma)*math.sin(beta)*math.cos(alpha) + math.sin(gamma)*math.sin(alpha))\n",
    "    matrix.append(row1)\n",
    "    row2 = []\n",
    "    row2.append(math.cos(beta) * math.sin(alpha))\n",
    "    row2.append(math.sin(gamma)*math.sin(beta)*math.sin(alpha) + math.cos(gamma)*math.cos(alpha))\n",
    "    row2.append(math.cos(gamma)*math.sin(beta)*math.sin(alpha) - math.sin(gamma)*math.cos(alpha))\n",
    "    matrix.append(row2)\n",
    "    row3 = []\n",
    "    row3.append(-math.sin(beta))\n",
    "    row3.append(math.sin(gamma)*math.cos(beta))\n",
    "    row3.append(math.cos(gamma)*math.cos(beta))\n",
    "    matrix.append(row3)\n",
    "    return matrix\n",
    "\n",
    "# Function that converts a given quarternion to a rotation matrix\n",
    "def QTM(qx, qy, qz, qw):\n",
    "    #  qw is the real part of the quarternion\n",
    "    matrix = []\n",
    "    row1 = []\n",
    "    row1.append(1 - 2 * qy**2 - 2 * qz**2)\n",
    "    row1.append(2 * qx * qy + 2 * qz * qw)\n",
    "    row1.append(2 * qx * qz - 2 * qy * qw)\n",
    "    matrix.append(row1)\n",
    "    row2 = []\n",
    "    row2.append(2 * qx * qy - 2 * qz * qw)\n",
    "    row2.append(1 - 2 * qx**2 - 2 * qz**2)\n",
    "    row2.append(2 * qy * qz + 2 * qx * qw)\n",
    "    matrix.append(row2)\n",
    "    row3 = []\n",
    "    row3.append(2 * qx * qz + 2 * qy * qw)\n",
    "    row3.append(2 * qy * qz - 2 * qx * qw)\n",
    "    row3.append(1 - 2 * qx**2 - 2 * qy**2)\n",
    "    matrix.append(row3)\n",
    "    return matrix\n",
    "\n",
    "# Function that converts a given rotation matrix to a quarternion\n",
    "def MTQ(m):\n",
    "    ans = []\n",
    "    if m[2][2] < 0:\n",
    "        if m[0][0] > m[1][1]:\n",
    "            trace = 1 + m[0][0] - m[1][1] - m[2][2]\n",
    "            ans.append(trace)\n",
    "            ans.append(m[0][1] + m[1][0])\n",
    "            ans.append(m[2][0] + m[0][2])\n",
    "            ans.append(m[1][2] - m[2][1])\n",
    "        else:\n",
    "            trace = 1 - m[0][0] + m[1][1] - m[2][2]\n",
    "            ans.append(m[0][1] + m[1][0])\n",
    "            ans.append(trace)\n",
    "            ans.append(m[1][2] + m[2][1])\n",
    "            ans.append(m[2][0] - m[0][2])\n",
    "    else:\n",
    "        if m[0][0] < -m[1][1]:\n",
    "            trace = 1 - m[0][0] - m[1][1] + m[2][2]\n",
    "            ans.append(m[0][2] + m[2][0])\n",
    "            ans.append(m[1][2] + m[2][1])\n",
    "            ans.append(trace)\n",
    "            ans.append(m[0][1] - m[1][0])\n",
    "        else:\n",
    "            trace = 1 + m[0][0] + m[1][1] + m[2][2]\n",
    "            ans.append(m[1][2] - m[2][1])\n",
    "            ans.append(m[2][0] - m[0][2])\n",
    "            ans.append(m[0][1] - m[1][0])\n",
    "            ans.append(trace)\n",
    "    ans = np.array(ans)\n",
    "    ans = ans / math.sqrt(trace) * 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cbef6",
   "metadata": {},
   "source": [
    "### Gimbal Lock\n",
    "\n",
    "- We can achieve the desired orientation using Euler rotations by combining multiple euler transformations. However, the rotations about different axes depend upon each other. We can say that transformations can change the asis of coordinate system. \n",
    "\n",
    "- In some situations, two of the axes can line up perfectly. In this case, rotating two of the axes has the same effect. In totality, we are left with only 2 dimensions of movement and we have lost a degree of freedom. This locking type of phenomenon is know as the Gimbal Lock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd9aa9",
   "metadata": {},
   "source": [
    "### Rotation matrix for airplane increasing pitch by 90 degreees\n",
    "\n",
    "For $ \\beta = \\pi / 2$ \n",
    "\n",
    "$R_{gmb \\beta}$ = $\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & cos(\\gamma) & -sin(\\gamma) \\\\ 0 & sin(\\gamma) & cos(\\gamma) \\end{bmatrix}$ $\\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ -1 & 0 & 0 \\end{bmatrix}$ $\\begin{bmatrix} cos(\\alpha) & -sin(\\alpha) & 0 \\\\ sin(\\alpha) & cos(\\alpha) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ \n",
    "\n",
    "$R_{gmb \\beta}$ = $\\begin{bmatrix} 0 & 0 & 1 \\\\ cos(\\gamma)sin(\\alpha) + cos(\\alpha)sin(\\gamma) & cos(\\gamma)cos(\\alpha) - sin(\\alpha)sin(\\gamma) & 0 \\\\ -cos(\\gamma)cos(\\alpha) + sin(\\alpha)sin(\\gamma) &  cos(\\gamma)sin(\\alpha) + cos(\\alpha)sin(\\gamma) & 0 \\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1767d",
   "metadata": {},
   "source": [
    "$P_{new} = R_{gmb \\beta} * P$ = $\\begin{bmatrix} 0 & 0 & 1 \\\\ cos(\\gamma)sin(\\alpha) + cos(\\alpha)sin(\\gamma) & cos(\\gamma)cos(\\alpha) - sin(\\alpha)sin(\\gamma) & 0 \\\\ -cos(\\gamma)cos(\\alpha) + sin(\\alpha)sin(\\gamma) &  cos(\\gamma)sin(\\alpha) + cos(\\alpha)sin(\\gamma) & 0 \\end{bmatrix}$ $\\begin{bmatrix} 0 \\\\ 1  \\\\ 0  \\end{bmatrix}$\n",
    "\n",
    "= $\\begin{bmatrix} 0 \\\\ cos(\\gamma)cos(\\alpha) - sin(\\alpha)sin(\\gamma) \\\\ cos(\\gamma)sin(\\alpha) + cos(\\alpha)sin(\\gamma) \\end{bmatrix}$\n",
    "\n",
    "= $\\begin{bmatrix} 0 \\\\ sin(\\alpha + \\gamma) \\\\ cos(\\alpha + \\gamma) \\end{bmatrix}$\n",
    "\n",
    "1. $P_{new} = [1, 0, 0]ᵀ $ is not possibleas the first entry of $P_{new}$ has to be zero\n",
    "\n",
    "2. If $P_{new}$ lies on the XY unit cicle, then, it's z coordinate will be zero and the sum of squares of the x and y coordinates will be 1. However, $P_{new}$ has to have x coordinate as 0. Therefore, y coordinate has to be +1 or -1. Therefore $P_{new} = [0, +1, 0]ᵀ$ and $P = [0, -1, 0]ᵀ$ are two posible solutions. Now, if $ cos(\\alpha + \\gamma) = 0 $ and $ sin(\\alpha + \\gamma)  = +1 , -1 $, then this gives us infinte solutions for $ \\alpha + \\gamma $ where their sum is either $\\pi/2$ or $-\\pi/2$.\n",
    "\n",
    "3. If $P_{new}$ lies on the YZ unit cicle, then for any y belonging to {0,1}, we can get an $z^2$ = {1 - $y^2$}. Therefore, wehave infiite possibilities for $P_{new}$. Now, $cos(\\alpha + \\gamma)^2$ + $sin(\\alpha + \\gamma)^2$ is always 1 which is already satisfied by the equation: $z^2$ = 1 - $y^2$. Therefore, we will be able to get $ \\alpha,  \\gamma $ for all these solutions. \n",
    "\n",
    "- The value of 90 degrees as $ \\beta $ is a problematic value because it results in the issue of gimbal lock. One dimension of movement gets inhibited and hence is an issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e69fddc",
   "metadata": {
    "id": "0e69fddc"
   },
   "source": [
    "## 3. Transformations and Homogeneous Coordinates\n",
    "\n",
    "1. Watch this [video](https://www.youtube.com/watch?v=PvEl63t-opM) to briefly understand homogeneous coordinates. \n",
    "    1. What are points at infinity? What type of transformation can you apply to transform a point from infinity to a point that is not at infinity? \n",
    "    2. Find the vanishing point for the given images in the **data/Q3** folder. Complete function **FilterLines()** and  **GetVanishingPoint()** in the given starter code.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Using homogeneous coordinates we can represent different types of transformation as point transforms vs. frame transforms. Concatenation of transforms (whether you post multiply transformation matrices or pre-multiply transformation matrices) depends on the problem and how you are viewing it. Try to understand the difference between frame vs. point transformations from this [video](https://youtu.be/Za7Sdegf8m8?t=1834). We have 5 camera frames A, B, C, D and E. Given *frame* transformation $A \\rightarrow B$ ,  $B \\rightarrow C$ ,  $D \\rightarrow C$ ,  $D \\rightarrow E$. Compute *frame transformation*  $D \\rightarrow E$. Also, given the co-ordinates of a point *x* in *D's* frame, what transformation is required to get *x's*  co-ordinates in *E's* frame? \n",
    "\n",
    "    <img src=\"img/3.jpeg\"  width=\"500\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860378b",
   "metadata": {},
   "source": [
    "### What are points at infinity? \n",
    "\n",
    "- In geometry, is is considered to be an ideal point or an idealizing limit used to depict the end of each line.\n",
    "\n",
    "- In projective geometry, a pair of lines can be said to determine a  point similar to the fact that a pair of points can determine a line. It is said to be the point which is at the end of two parallel lines or basically the point which is supposed to be the intersection of these two parallels.      \n",
    "\n",
    "- In homogeneous coordinates, it represents a point that gives us a sense of direction but is infinitely far away in that direction.\n",
    "\n",
    "### What type of transformation can you apply to transform a point from infinity to a point that is not at infinity\n",
    "\n",
    "- When we represent a vector in a homogeneous coordinate system, we add another dimension to the vector in the matrix representation. If we have a vector `<x, y, z>` in a 3 dimensional space, we can represent it as `[x', y', z', w]'` where w represents the added dimension. Now, `x = x'/w, y = y'/w and z = z'/w` are the corresponding relations. Therefore, if we have `w = 1`, we can easily map homogeneous coordinates to our original coordiante system.\n",
    "\n",
    "- Wer can apply these homogeneous transformations to represent points at infinity. In this case, the value of w will be 0. And hence x, y, z all will be values obtained after dividing by zero leading to the tendency of infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3917ed0",
   "metadata": {
    "id": "b3917ed0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ReadImage(InputImagePath):\n",
    "    Images = []                     # Input Images will be stored in this list.\n",
    "    ImageNames = []                 # Names of input images will be stored in this list.\n",
    "    \n",
    "    # Checking if path is of file or folder.\n",
    "    if os.path.isfile(InputImagePath):\t\t\t\t\t\t    # If path is of file.\n",
    "        InputImage = cv2.imread(InputImagePath)                 # Reading the image.\n",
    "        \n",
    "        # Checking if image is read.\n",
    "        if InputImage is None:\n",
    "            print(\"Image not read. Provide a correct path\")\n",
    "            exit()\n",
    "        \n",
    "        Images.append(InputImage)                               # Storing the image.\n",
    "        ImageNames.append(os.path.basename(InputImagePath))     # Storing the image's name.\n",
    "\n",
    "\t# If path is of a folder contaning images.\n",
    "    elif os.path.isdir(InputImagePath):\n",
    "\t\t# Getting all image's name present inside the folder.\n",
    "        for ImageName in os.listdir(InputImagePath):\n",
    "\t\t\t# Reading images one by one.\n",
    "            InputImage = cv2.imread(InputImagePath + \"/\" + ImageName)\n",
    "\t\t\t\n",
    "            Images.append(InputImage)\t\t\t\t\t\t\t# Storing images.\n",
    "            ImageNames.append(ImageName)                        # Storing image's names.\n",
    "        \n",
    "    # If it is neither file nor folder(Invalid Path).\n",
    "    else:\n",
    "        print(\"\\nEnter valid Image Path.\\n\")\n",
    "        exit()\n",
    "\n",
    "    return Images, ImageNames\n",
    "        \n",
    "def GetLines(Image):\n",
    "    # Converting to grayscale\n",
    "    GrayImage = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "    # Blurring image to reduce noise.\n",
    "    BlurGrayImage = cv2.GaussianBlur(GrayImage, (5, 5), 1)\n",
    "    # Generating Edge image\n",
    "    EdgeImage = cv2.Canny(BlurGrayImage, 40, 255)\n",
    "\n",
    "    # Finding Lines in the image\n",
    "    Lines = cv2.HoughLinesP(EdgeImage, 1, np.pi / 180, 50, 10, 15)\n",
    "\n",
    "    # Check if lines found and exit if not.\n",
    "    if Lines is None:\n",
    "        print(\"Not enough lines found in the image for Vanishing Point detection.\")\n",
    "        exit(0)\n",
    "    \n",
    "    return Lines\n",
    "    \n",
    "def FilterLines(Lines):\n",
    "    output = []\n",
    "    maxLines = 100 # Maximum number of lines to be considered.\n",
    "    critAngle = 5 # To Avoid Taking lines close to 0 or 90 degrees\n",
    "    maxSlope = 1e5 # To represent Perpendicular lines.\n",
    "\n",
    "    for everyLine in Lines:    \n",
    "        # Getting the end points of the line.\n",
    "        [x1, y1, x2, y2] = everyLine[0]   \n",
    "        \n",
    "        Slope = maxSlope\n",
    "        if x1 != x2:\n",
    "            Slope = (y2 - y1) / (x2 - x1)\n",
    "            \n",
    "        yIntercept = y2 - (Slope * x2)\n",
    "        # y = mx + yIntercept\n",
    "        \n",
    "        angle = abs(math.degrees(math.atan(Slope)))\n",
    "        if angle >= critAngle: # Avoid Horizontal lines.\n",
    "            if angle <= 90 - critAngle: # Avoid Vertical lines.\n",
    "                lengthLine = math.sqrt((y2 - y1) * (y2 - y1) + (x2 - x1) * (x2 - x1))\n",
    "                output.append([Slope, yIntercept, lengthLine, x1, y1, x2, y2])\n",
    "    \n",
    "    # Sorting the lines based on length and taking the best few lines out of all.\n",
    "    output = sorted(output, key=lambda x: x[2])\n",
    "    if(len(output) > maxLines):\n",
    "        output = output[:maxLines]\n",
    "\n",
    "    return output \n",
    "\n",
    "def GetVanishingPoint(lines):\n",
    "    err = 1e5 # To store minimum error across all points.\n",
    "    ans = None \n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        for j in range(i + 1, len(lines)):\n",
    "            slope1, intercept1 = lines[i][0], lines[i][1]\n",
    "            slope2, intercept2 = lines[j][0], lines[j][1]\n",
    "            if slope1 != slope2: # Avoiding parallel lines.\n",
    "                pointError = 0\n",
    "                xIntersect = (intercept2 - intercept1) / (slope1 - slope2)\n",
    "                yIntersect = slope1 * xIntersect + intercept1\n",
    "                for k in range(len(lines)): # Calculating error by iterating over all lines.\n",
    "                    slope3, intercept3 = lines[k][0], lines[k][1]\n",
    "                    perpSlope = -1 / slope3\n",
    "                    newIntercept = yIntersect - perpSlope * xIntersect\n",
    "                    xInt = (intercept3 - newIntercept) / (perpSlope - slope3) # X Intersection with perpendicular line.\n",
    "                    yInt = perpSlope * xInt + newIntercept # Y Intersection with perpendicular line.\n",
    "                    # Distance between the two points of intersection.\n",
    "                    leng = math.sqrt((xInt - xIntersect) * (xInt - xIntersect)  + (yInt - yIntersect) * (yInt - yIntersect))\n",
    "                    pointError += leng*leng\n",
    "                pointError = math.sqrt(pointError)\n",
    "                if pointError < err:  # Chek if new error is less than current minimum\n",
    "                    err = pointError\n",
    "                    ans = [xIntersect, yIntersect] # If error is minimum, the new point is the answer.\n",
    "    return ans\n",
    "\n",
    "Images, ImageNames = ReadImage(\"./data/Q3/\")            # Reading all input images\n",
    "\n",
    "\n",
    "for i in range(len(Images)):\n",
    "    Image = Images[i]\n",
    "\n",
    "    # Getting the lines form the image\n",
    "    Lines = GetLines(Image)\n",
    "\n",
    "    FilteredLines = FilterLines(Lines)\n",
    "    # Get vanishing point\n",
    "    VanishingPoint = GetVanishingPoint(FilteredLines)\n",
    "\n",
    "    # Checking if vanishing point found\n",
    "    if VanishingPoint is None:\n",
    "        print(\"Vanishing Point not found. Possible reason is that not enough lines are found in the image for determination of vanishing point.\")\n",
    "        continue\n",
    "\n",
    "    # Drawing lines and vanishing point\n",
    "    Lines = FilteredLines\n",
    "\n",
    "    for Line in Lines:\n",
    "        cv2.line(Image, (Line[3], Line[4]), (Line[5], Line[6]), (0, 255, 0), 2)\n",
    "    cv2.circle(Image, (int(VanishingPoint[0]), int(VanishingPoint[1])), 10, (0, 0, 255), -1)\n",
    "\n",
    "    # Showing the final image\n",
    "    cv2.imshow(\"OutputImage\", Image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206ac6",
   "metadata": {},
   "source": [
    "### Frame Transformations\n",
    "\n",
    "Let us consider $P^{A}$ to be the position vector of $\\vec P$ in frame A.\n",
    "\n",
    "Let $T_{A}^{B}$ be the homogeneous transformation matrix of frame A relative to B. Hence, multiplying a vetor in frame B with this matrix would yield us the mapping of the point in frame A. Therefore, $P^{B}$ = $T_{A}^{B}P^{A}$ (The notation which I have used is different from the one given in the question)\n",
    "\n",
    "\n",
    "Therefore we are given: $T_{A}^{B}$, $T_{B}^{C}$, $T_{D}^{C}$ and $T_{A}^{E}$.\n",
    "\n",
    "Now we want to obtain : $T_{D}^{E}$\n",
    "\n",
    "We can use the statement: $P^{E}$ = $T_{D}^{E}P^{D}$ \n",
    "\n",
    "Now, $P^{E}$ = $T_{A}^{E}P^{A}$\n",
    "Also, $P^{A}$ = $T_{B}^{A}P^{B}$. But we have $T_{A}^{B}$ which is nothing but the inverse of $T_{B}^{A}$. \n",
    "\n",
    "So, $T_{B}^{A}$ = $(T_{A}^{B})^{-1}$  \n",
    "Therefore, Now, $P^{E}$ = $T_{A}^{E}P^{A}$ = $T_{A}^{E} (T_{A}^{B})^{-1} P^{B} $\n",
    "\n",
    "Now, $P^{B}$ = $T_{C}^{B}P^{C}$\n",
    "Also, $P^{C}$ = $T_{B}^{C}P^{B}$. But we have $T_{B}^{C}$ which is nothing but the inverse of $T_{C}^{B}$. \n",
    "\n",
    "So, $T_{C}^{B}$ = $(T_{B}^{C})^{-1}$  \n",
    "Therefore, Now, $P^{E}$ = $T_{A}^{E} (T_{A}^{B})^{-1} P^{B} $ = $T_{A}^{E} (T_{A}^{B})^{-1} (T_{B}^{C})^{-1} P^{C} $\n",
    "\n",
    "Now, $P^{C}$ = $T_{D}^{C}P^{D}$\n",
    "\n",
    "Therefore, Now, $P^{E}$ = $T_{A}^{E} (T_{A}^{B})^{-1} (T_{B}^{C})^{-1} P^{C}$ = $T_{A}^{E} (T_{A}^{B})^{-1} (T_{B}^{C})^{-1} T_{D}^{C}P^{D} $\n",
    "\n",
    "Now comparing with the original statement:\n",
    "\n",
    "$T_{D}^{E} = T_{A}^{E} (T_{A}^{B})^{-1} (T_{B}^{C})^{-1} T_{D}^{C}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf963302",
   "metadata": {},
   "source": [
    "Now, the last part of the question also asks us to find $T_{E}^{D}$ whih will be nothing but the inverse of $T_{D}^{E}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f08d84",
   "metadata": {
    "id": "e5f08d84"
   },
   "source": [
    "## 4. LiDAR and Registration\n",
    "\n",
    "Point clouds are a collection of points that represent a 3D shape or feature. Each point has its own set of X, Y and Z coordinates and in some cases additional attributes. A popular way to obtain this is by photogrammetry, though here we will use LiDAR data.\n",
    "\n",
    "LiDAR is a remote sensing process which collects measurements used to create 3D models and maps of objects and environments. Using ultraviolet, visible, or near-infrared light, LiDAR gauges spatial relationships and shapes by measuring the time it takes for signals to bounce off objects and return to the scanner.\n",
    "\n",
    "Download the data from [here](https://iiitaphyd-my.sharepoint.com/:f:/g/personal/venkata_surya_students_iiit_ac_in/EnYAMaTVIhJItzKYqtahE30BRKB6p6UfHN3TyJzvo6Mw0g?e=PegWds). It contains the LIDAR sensor output and odometry information per frame.\n",
    "\n",
    "  The .bin files contain the 3D point cloud captured by the LIDAR in this format - x, y, z, and reflectance. \n",
    "\n",
    "  The odometry information is given in the `odometry.txt` file, which is a 12 element vector. Reshape each of the first 77 rows to a 3x4 matrix to obtain the pose.\n",
    "    \n",
    "The point cloud obtained is with respect to the LiDAR frame. The poses however, are in the camera frame. If we want to combine the point clouds from various frames, we need to bring them to the camera frame. \n",
    "\n",
    "1. Refer to the image below and apply the required transformation to the point cloud. \n",
    "<br>\n",
    "\n",
    "    <img src=\"img/4.jpeg\"  width=\"500\" >\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Then, register all point clouds into a common reference frame and visualise it (Open3D). It is helpful to use homogeneous coordinates to keep track of the different frames.\n",
    "\n",
    "3. Write a function to transform the registered point cloud from the world to the $i^{th}$ camera frame, wherein $i$ is the input to the function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "directed-termination",
   "metadata": {
    "id": "directed-termination"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "storeData = []\n",
    "nameFile = \"./data/Q4/LiDAR/0000\"\n",
    "for i in range(10, 87):\n",
    "    x = nameFile + str(i) + \".bin\"\n",
    "    binPcd = np.fromfile(x, dtype=np.float32)\n",
    "    binPcd = binPcd.reshape((-1, 4))[:, 0:3]\n",
    "    storeData.append(binPcd)\n",
    "\n",
    "storeData = np.array(storeData, dtype=object)\n",
    "\n",
    "odoFile = \"./data/Q4/odometry.txt\"\n",
    "filePtr = open(odoFile, \"r\")\n",
    "matrix = []\n",
    "for i in range(77):\n",
    "    row = (filePtr.readline()).split()\n",
    "    rowInMatrix= np.array(list(map(float, row)))\n",
    "    rowInMatrix = np.reshape(rowInMatrix, (3, 4))\n",
    "    matrix.append(rowInMatrix)\n",
    "\n",
    "lidToCam = np.array([[0,0,1,0],[-1,0,0,0], [0,-1,0,0],[0,0,0,1]])\n",
    "lidToCam = np.transpose(lidToCam)\n",
    "\n",
    "allPoses = []\n",
    "for i in range(77):\n",
    "    numPoints = storeData[i].shape[0]\n",
    "    currPose = []\n",
    "    for j in range(numPoints):\n",
    "        homoVec = np.array([storeData[i][j][0], storeData[i][j][1], storeData[i][j][2], 1])\n",
    "        convertedVec = np.matmul(lidToCam, homoVec)\n",
    "        currPose.append(convertedVec)\n",
    "    allPoses.append(currPose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea788c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "homoMatrix = []\n",
    "for i in range(77):\n",
    "    curr = np.array([[matrix[i][0][0], matrix[i][0][1], matrix[i][0][2], matrix[i][0][3]], [matrix[i][1][0], matrix[i][1][1], matrix[i][1][2], matrix[i][1][3]], [matrix[i][2][0], matrix[i][2][1], matrix[i][2][2], matrix[i][2][3]], [0,0,0,1]]) \n",
    "    homoMatrix.append(curr)\n",
    "worldFrame = np.array([[0,0,1,0],[-1,0,0,0], [0,-1,0,0] ,[0,0,0,1]])\n",
    "ctw = []\n",
    "wtc = []\n",
    "for i in range(77):\n",
    "    ctw.append(np.matmul(worldFrame, homoMatrix[i]))\n",
    "    wtc.append(np.linalg.inv(ctw[i]))\n",
    "\n",
    "inCommonFrame = []\n",
    "for i in range(77):\n",
    "    allPoses[i] = np.array(allPoses[i])\n",
    "    extent = allPoses[i].shape[0]\n",
    "    for j in range(extent):\n",
    "        inCommonFrame.append(np.matmul(homoMatrix[i], allPoses[i][j])[0:3])\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(inCommonFrame)\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c706ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCamera(x, pcd):\n",
    "    o3d.visualization.draw_geometries([pcd.transform(wtc[x])])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MR 2022 A1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('a1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b3f52620082b85678dcf4b922e5cd3966d9a4f9264ed046017a0a585fc8a1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
